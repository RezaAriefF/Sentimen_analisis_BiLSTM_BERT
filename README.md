# Sentimen_analisis_BiLSTM_BERT
sentimen analisis using Bidirecrional LSTM and BERT Tokenizer
 # Sentiment Analysis using BiLSTM and BERT

This repository contains a sentiment analysis project that leverages BiLSTM (Bidirectional Long Short-Term Memory) and BERT (Bidirectional Encoder Representations from Transformers) models to classify text data into positive, negative, or neutral sentiments. The project is designed to provide a comprehensive solution for sentiment analysis using state-of-the-art deep learning techniques.

## Features

- **Preprocessing**: Text data preprocessing including tokenization, stopword removal, and text normalization.
- **BiLSTM Model**: Implementation of a BiLSTM model for sentiment classification.
- **BERT Model**: Implementation of a BERT model for sentiment classification.
- **Training and Evaluation**: Scripts for training and evaluating the models on sentiment analysis datasets.
- **Visualization**: Visualization of training metrics and model performance.
- **Pretrained Models**: Utilization of pretrained BERT models from the Hugging Face library.

## Results

The repository provides detailed logs and visualizations of the training process, along with evaluation metrics for both BiLSTM and BERT models, allowing for an in-depth analysis of their performance on sentiment classification tasks.


## Acknowledgements

- [Hugging Face](https://huggingface.co/) for providing pretrained BERT models.
- The deep learning community for continuous contributions and research advancements.

---

Feel free to reach out if you have any questions or need further assistance with this project. Happy coding!

To run this program use "streamlit run app.py"
in app.py have code streamlit to run web app for impementing models from BiLSTM and BERT Tokenizer.
